{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13899803,"sourceType":"datasetVersion","datasetId":8855638}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip uninstall -y numpy\n!pip install \"numpy<2\"\n!pip install --upgrade pip setuptools wheel\n\n# Optional: install CPU torch & torchvision (Kaggle often has torch; this ensures CPU wheel)\n!pip install torch --extra-index-url https://download.pytorch.org/whl/cpu\n!pip install torchvision","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T14:51:39.388151Z","iopub.execute_input":"2025-11-28T14:51:39.388354Z","iopub.status.idle":"2025-11-28T14:53:24.940607Z","shell.execute_reply.started":"2025-11-28T14:51:39.388324Z","shell.execute_reply":"2025-11-28T14:53:24.939369Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: numpy 1.26.4\nUninstalling numpy-1.26.4:\n  Successfully uninstalled numpy-1.26.4\nCollecting numpy<2\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: numpy\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ndatasets 4.4.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\nopencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\nopencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\nopencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\ntensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\numap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed numpy-1.26.4\nRequirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\nCollecting pip\n  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (75.2.0)\nCollecting setuptools\n  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\nRequirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (0.45.1)\nDownloading pip-25.3-py3-none-any.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: setuptools, pip\n  Attempting uninstall: setuptools\n    Found existing installation: setuptools 75.2.0\n    Uninstalling setuptools-75.2.0:\n      Successfully uninstalled setuptools-75.2.0\n  Attempting uninstall: pip\n    Found existing installation: pip 24.1.2\n    Uninstalling pip-24.1.2:\n      Successfully uninstalled pip-24.1.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\ntensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed pip-25.3 setuptools-80.9.0\nLooking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cpu\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.20.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.15.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.10.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.3)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m130.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m148.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m  \u001b[33m0:00:06\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m123.2 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m119.3 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m6m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n\u001b[2K  Attempting uninstall: nvidia-nvjitlink-cu12\n\u001b[2K    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n\u001b[2K    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n\u001b[2K      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82/10\u001b[0m [nvidia-nvjitlink-cu12]\n\u001b[2K  Attempting uninstall: nvidia-curand-cu12━━━━━━\u001b[0m \u001b[32m 0/10\u001b[0m [nvidia-nvjitlink-cu12]\n\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.6.820m [nvidia-nvjitlink-cu12]\n\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.6.82:0m \u001b[32m 0/10\u001b[0m [nvidia-nvjitlink-cu12]\n\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.6.82━━━━━━━\u001b[0m \u001b[32m 1/10\u001b[0m [nvidia-curand-cu12]\n\u001b[2K  Attempting uninstall: nvidia-cufft-cu12━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/10\u001b[0m [nvidia-curand-cu12]\n\u001b[2K    Found existing installation: nvidia-cufft-cu12 11.2.3.61━━\u001b[0m \u001b[32m 1/10\u001b[0m [nvidia-curand-cu12]\n\u001b[2K    Uninstalling nvidia-cufft-cu12-11.2.3.61:━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/10\u001b[0m [nvidia-curand-cu12]\n\u001b[2K      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61━━━━━━━━\u001b[0m \u001b[32m 2/10\u001b[0m [nvidia-cufft-cu12]\n\u001b[2K  Attempting uninstall: nvidia-cuda-runtime-cu12━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/10\u001b[0m [nvidia-cufft-cu12]\n\u001b[2K    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82m \u001b[32m 2/10\u001b[0m [nvidia-cufft-cu12]\n\u001b[2K    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:━━━━━━━━━━━━\u001b[0m \u001b[32m 2/10\u001b[0m [nvidia-cufft-cu12]\n\u001b[2K      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82━━━\u001b[0m \u001b[32m 3/10\u001b[0m [nvidia-cuda-runtime-cu12]\n\u001b[2K  Attempting uninstall: nvidia-cuda-nvrtc-cu12━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/10\u001b[0m [nvidia-cuda-runtime-cu12]\n\u001b[2K    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82[0m \u001b[32m 3/10\u001b[0m [nvidia-cuda-runtime-cu12]\n\u001b[2K    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/10\u001b[0m [nvidia-cuda-runtime-cu12]\n\u001b[2K      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82━━━━━\u001b[0m \u001b[32m 4/10\u001b[0m [nvidia-cuda-nvrtc-cu12]\n\u001b[2K  Attempting uninstall: nvidia-cuda-cupti-cu12━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/10\u001b[0m [nvidia-cuda-nvrtc-cu12]\n\u001b[2K    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82━━━\u001b[0m \u001b[32m 5/10\u001b[0m [nvidia-cuda-cupti-cu12]\n\u001b[2K    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/10\u001b[0m [nvidia-cuda-cupti-cu12]\n\u001b[2K      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82━━━━━\u001b[0m \u001b[32m 5/10\u001b[0m [nvidia-cuda-cupti-cu12]\n\u001b[2K  Attempting uninstall: nvidia-cublas-cu12\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/10\u001b[0m [nvidia-cuda-cupti-cu12]\n\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.5.3.2━━━━━━\u001b[0m \u001b[32m 6/10\u001b[0m [nvidia-cublas-cu12]\n\u001b[2K    Uninstalling nvidia-cublas-cu12-12.5.3.2:0m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/10\u001b[0m [nvidia-cublas-cu12]\n\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2━━━━━━━━\u001b[0m \u001b[32m 6/10\u001b[0m [nvidia-cublas-cu12]\n\u001b[2K  Attempting uninstall: nvidia-cusparse-cu120m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/10\u001b[0m [nvidia-cublas-cu12]\n\u001b[2K    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\u001b[0m \u001b[32m 6/10\u001b[0m [nvidia-cublas-cu12]\n\u001b[2K    Uninstalling nvidia-cusparse-cu12-12.5.1.3:━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/10\u001b[0m [nvidia-cublas-cu12]\n\u001b[2K      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3━━━━━━\u001b[0m \u001b[32m 7/10\u001b[0m [nvidia-cusparse-cu12]\n\u001b[2K  Attempting uninstall: nvidia-cudnn-cu12[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m 7/10\u001b[0m [nvidia-cusparse-cu12]\n\u001b[2K    Found existing installation: nvidia-cudnn-cu12 9.3.0.75━━━\u001b[0m \u001b[32m 7/10\u001b[0m [nvidia-cusparse-cu12]\n\u001b[2K    Uninstalling nvidia-cudnn-cu12-9.3.0.75:0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m 7/10\u001b[0m [nvidia-cusparse-cu12]\n\u001b[2K      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.750m━━━━━━━\u001b[0m \u001b[32m 8/10\u001b[0m [nvidia-cudnn-cu12]\n\u001b[2K  Attempting uninstall: nvidia-cusolver-cu12\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m 8/10\u001b[0m [nvidia-cudnn-cu12]\n\u001b[2K    Found existing installation: nvidia-cusolver-cu12 11.6.3.83[0m \u001b[32m 8/10\u001b[0m [nvidia-cudnn-cu12]\n\u001b[2K    Uninstalling nvidia-cusolver-cu12-11.6.3.83:0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m 8/10\u001b[0m [nvidia-cudnn-cu12]\n\u001b[2K      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.830m━━━\u001b[0m \u001b[32m 9/10\u001b[0m [nvidia-cusolver-cu12]\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/10\u001b[0m [nvidia-cusolver-cu12]dia-cusolver-cu12]\n\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.6.0+cu124)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.3.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.20.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (4.15.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2025.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->torchvision) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->torchvision) (3.0.3)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# CELL 0 — copy first non-empty /kaggle/input dataset into writable /kaggle/working/dataset_copy\nimport shutil, os\nfrom pathlib import Path\n\nINPUT_ROOT = Path(\"/kaggle/input\")\nWORK_COPY = Path(\"/kaggle/working/dataset_copy\").resolve()\n\n# find first non-empty input subfolder\ncand = None\nfor p in sorted(INPUT_ROOT.iterdir()):\n    try:\n        if p.is_dir() and any(p.rglob(\"*\")):\n            cand = p\n            break\n    except Exception:\n        continue\n\nif cand is None:\n    print(\"No dataset found under /kaggle/input. If your data is already in /kaggle/working, you can skip copying.\")\nelse:\n    print(\"Found input folder to copy:\", cand)\n    # prefer nested classification-like folder if obvious\n    nested = None\n    for sub in cand.rglob(\"*\"):\n        try:\n            if sub.is_dir() and any(x.name.lower() in (\"train\",\"valid\",\"val\",\"classification_dataset\") for x in sub.iterdir() if x.is_dir()):\n                nested = sub\n                break\n        except Exception:\n            continue\n    src = nested if nested is not None else cand\n    print(\"Using source folder:\", src)\n    if WORK_COPY.exists():\n        print(\"Destination already exists:\", WORK_COPY, \"- skipping copy (delete to force refresh).\")\n    else:\n        print(\"Copying to writable working folder:\", WORK_COPY)\n        shutil.copytree(src, WORK_COPY, dirs_exist_ok=True)\n        (WORK_COPY / \".copied_from\").write_text(str(src))\n        print(\"Copy complete. WORK_COPY contents top-level:\", list(WORK_COPY.iterdir())[:20])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T14:53:41.497234Z","iopub.execute_input":"2025-11-28T14:53:41.498353Z","iopub.status.idle":"2025-11-28T14:53:41.511701Z","shell.execute_reply.started":"2025-11-28T14:53:41.498314Z","shell.execute_reply":"2025-11-28T14:53:41.510537Z"}},"outputs":[{"name":"stdout","text":"Found input folder to copy: /kaggle/input/classification-zip\nUsing source folder: /kaggle/input/classification-zip/classification_dataset\nDestination already exists: /kaggle/working/dataset_copy - skipping copy (delete to force refresh).\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# CELL 1 — dataset check\nfrom pathlib import Path\nimport os\n\n# Use the writable copy created by CELL 0\nWORK_ROOT = Path(\"/kaggle/working/dataset_copy/classification_dataset\")\n# Common case: dataset copied directly under /kaggle/working/dataset_copy (no extra nesting)\nif not WORK_ROOT.exists():\n    # try fallback locations under dataset_copy\n    alt1 = Path(\"/kaggle/working/dataset_copy\")\n    # prefer a folder containing 'train' and 'valid' inside dataset_copy\n    if alt1.exists():\n        for p in alt1.iterdir():\n            if p.is_dir() and (p / \"train\").exists() and (p / \"valid\").exists():\n                WORK_ROOT = p\n                break\n    # final fallback: if dataset_copy itself contains train/valid, use it\n    if (alt1 / \"train\").exists() and (alt1 / \"valid\").exists():\n        WORK_ROOT = alt1\n\nARTIFACT_DIR = Path(\"/kaggle/working/artifacts\")\nARTIFACT_DIR.mkdir(parents=True, exist_ok=True)\nCHECKPOINT = ARTIFACT_DIR / \"classification_model.pt\"  # existing model you trained earlier\n\nprint(\"WORK_ROOT:\", WORK_ROOT)\nassert WORK_ROOT.exists(), f\"WORK_ROOT not found: {WORK_ROOT}. If your dataset is under a different folder, inspect /kaggle/working/dataset_copy.\"\n\nfor p in sorted(WORK_ROOT.iterdir()):\n    print(p.name, \"(dir)\" if p.is_dir() else \"\")\n\n# check train/valid presence\ntrain_dir = WORK_ROOT / \"train\"\nval_dir = WORK_ROOT / \"valid\"\nif not train_dir.exists():\n    # try 'train_images' or fallback to using WORK_ROOT itself\n    for alt in [\"train_images\",\"training\"]:\n        if (WORK_ROOT/alt).exists():\n            train_dir = WORK_ROOT/alt\n            break\n\nprint(\"train_dir:\", train_dir, \"exists:\", train_dir.exists())\nprint(\"val_dir:\", val_dir, \"exists:\", val_dir.exists())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T14:54:44.907214Z","iopub.execute_input":"2025-11-28T14:54:44.907553Z","iopub.status.idle":"2025-11-28T14:54:44.918378Z","shell.execute_reply.started":"2025-11-28T14:54:44.907526Z","shell.execute_reply":"2025-11-28T14:54:44.917147Z"}},"outputs":[{"name":"stdout","text":"WORK_ROOT: /kaggle/working/dataset_copy\n.copied_from \ntest (dir)\ntrain (dir)\nvalid (dir)\ntrain_dir: /kaggle/working/dataset_copy/train exists: True\nval_dir: /kaggle/working/dataset_copy/valid exists: True\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# CELL 2 — dataloaders and classes\nimport torchvision.transforms as T\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader, random_split\nfrom pathlib import Path\nimport torch\n\nWORK_ROOT = Path(\"/kaggle/working/dataset_copy/classification_dataset\")  # canonical dataset copy root\n# fallback: if above not right, try top-level copy\nif not WORK_ROOT.exists():\n    WORK_ROOT = Path(\"/kaggle/working/dataset_copy\")\n\ntrain_dir = WORK_ROOT / \"train\"\nval_dir = WORK_ROOT / \"valid\"\n\n# transforms (simple)\ntrain_tf = T.Compose([T.Resize((224,224)), T.RandomHorizontalFlip(), T.ToTensor()])\nval_tf   = T.Compose([T.Resize((224,224)), T.ToTensor()])\n\n# Use ImageFolder (assumes folder-per-class under train/ and valid/)\ntrain_ds = ImageFolder(str(train_dir), transform=train_tf)\nval_ds = ImageFolder(str(val_dir), transform=val_tf)\n\nprint(\"Detected classes:\", train_ds.classes)\nprint(\"Num classes:\", len(train_ds.classes))\nprint(\"Train samples:\", len(train_ds), \"Val samples:\", len(val_ds))\n\n# Dataloaders\ntrain_loader = DataLoader(train_ds, batch_size=8, shuffle=True, num_workers=0)\nval_loader   = DataLoader(val_ds, batch_size=16, shuffle=False, num_workers=0)\n\n# Save class names to artifact for reproducibility\nimport json\nARTIFACT_DIR = Path(\"/kaggle/working/artifacts\"); ARTIFACT_DIR.mkdir(parents=True, exist_ok=True)\nwith open(ARTIFACT_DIR/\"class_names.json\",\"w\",encoding=\"utf-8\") as f:\n    json.dump(train_ds.classes, f)\nprint(\"Saved /kaggle/working/artifacts/class_names.json\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T14:55:03.810416Z","iopub.execute_input":"2025-11-28T14:55:03.810682Z","iopub.status.idle":"2025-11-28T14:55:10.745833Z","shell.execute_reply.started":"2025-11-28T14:55:03.810666Z","shell.execute_reply":"2025-11-28T14:55:10.744898Z"}},"outputs":[{"name":"stdout","text":"Detected classes: ['bird', 'drone']\nNum classes: 2\nTrain samples: 2662 Val samples: 442\nSaved /kaggle/working/artifacts/class_names.json\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# CELL 3 — model construction & robust checkpoint load\nimport torch\nfrom torchvision import models\nfrom pathlib import Path\nimport os\n\nARTIFACT_DIR = Path(\"/kaggle/working/artifacts\")\nARTIFACT_DIR.mkdir(parents=True, exist_ok=True)\nCHECKPOINT = ARTIFACT_DIR / \"classification_model.pt\"  # existing checkpoint (may have wrong fc size)\ndevice = \"cpu\"\n\n# number of classes detected from previous cell\nimport json\nclass_names = json.load(open(ARTIFACT_DIR/\"class_names.json\",\"r\",encoding=\"utf-8\"))\nnum_classes = len(class_names)\nprint(\"num_classes:\", num_classes, \"class_names:\", class_names)\n\n# build fresh model\nmodel = models.resnet18(weights=None)\nnum_ftrs = model.fc.in_features\n\n# Attempt to load checkpoint state dict robustly\ndef extract_state_dict(maybe_dict):\n    \"\"\"If checkpoint is wrapped, try to find inner state_dict, else return as-is.\"\"\"\n    if not isinstance(maybe_dict, dict):\n        return None\n    # common keys: 'model_state_dict', 'state_dict', 'net', 'model'\n    for key in (\"model_state_dict\",\"state_dict\",\"net\",\"state\"):\n        if key in maybe_dict and isinstance(maybe_dict[key], dict):\n            return maybe_dict[key]\n    # heuristics: if values look like tensors assume it's a state dict\n    if all(isinstance(v, torch.Tensor) or (hasattr(v,'shape') and not isinstance(v, dict)) for v in maybe_dict.values()):\n        return maybe_dict\n    # try to find the largest dict-valued entry\n    for k,v in maybe_dict.items():\n        if isinstance(v, dict) and any(isinstance(x, torch.Tensor) for x in v.values()):\n            return v\n    return None\n\nloaded = False\nif CHECKPOINT.exists():\n    ck = torch.load(CHECKPOINT, map_location=device)\n    state_dict = extract_state_dict(ck) or ck\n    # If state_dict contains fc shape mismatching, we will load with strict=False\n    try:\n        # create a temp model with fc sized like checkpoint if possible to allow better mapping\n        temp_model = models.resnet18(weights=None)\n        # if ck has 'fc.weight' we can inspect its first dimension\n        if 'fc.weight' in state_dict:\n            ck_fc_shape0 = state_dict['fc.weight'].shape[0]\n            # set temp model fc to same shape to allow exact load\n            import torch.nn as nn\n            temp_model.fc = nn.Linear(num_ftrs, ck_fc_shape0)\n            load_res = temp_model.load_state_dict(state_dict, strict=False)\n            print(\"Loaded into temp model. Missing/unexpected keys:\", load_res)\n            # now copy backbone weights into our real model (except fc)\n            ts = temp_model.state_dict()\n            my_sd = model.state_dict()\n            for k,v in ts.items():\n                if not k.startswith(\"fc.\"):\n                    my_sd[k] = v\n            model.load_state_dict(my_sd)\n            loaded = True\n            print(\"Backbone weights copied from checkpoint (fc skipped or mismatched).\")\n        else:\n            # state_dict lacks fc key — likely backbone-only checkpoint\n            model.load_state_dict(state_dict, strict=False)\n            loaded = True\n            print(\"Loaded checkpoint (no fc present) with strict=False.\")\n    except Exception as e:\n        print(\"Warning: robust load failed:\", e)\n        try:\n            model.load_state_dict(state_dict, strict=False)\n            loaded = True\n            print(\"Fallback loaded checkpoint with strict=False.\")\n        except Exception as e2:\n            print(\"Final load attempt failed — proceeding with randomly initialized model. Error:\", e2)\nelse:\n    print(\"No existing checkpoint found at\", CHECKPOINT, \"; proceeding from scratch.\")\n\n# Replace final fc with new layer for correct num_classes (random init)\nimport torch.nn as nn\nmodel.fc = nn.Linear(num_ftrs, num_classes)\nmodel.to(device)\nprint(\"Model ready. Final fc shape:\", model.fc.weight.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T14:55:37.348312Z","iopub.execute_input":"2025-11-28T14:55:37.348786Z","iopub.status.idle":"2025-11-28T14:55:37.504982Z","shell.execute_reply.started":"2025-11-28T14:55:37.348769Z","shell.execute_reply":"2025-11-28T14:55:37.504010Z"}},"outputs":[{"name":"stdout","text":"num_classes: 2 class_names: ['bird', 'drone']\nNo existing checkpoint found at /kaggle/working/artifacts/classification_model.pt ; proceeding from scratch.\nModel ready. Final fc shape: torch.Size([2, 512])\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# ---------- PRELIGHT TEST (single batch forward+backward) ----------\nimport torch, time\nfrom pathlib import Path\nfrom torchvision import models\nfrom torch import nn, optim\n\n# assume train_loader, val_loader, class_names were created by CELL 2\nprint(\"Sanity: train_loader size:\", len(train_loader), \"val:\", len(val_loader))\n# build model same as CELL 3 but simpler: new fc with correct classes\nnum_classes = len(class_names)\nmodel = models.resnet18(weights=None)\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, num_classes)\ndevice = \"cpu\"\nmodel.to(device)\nprint(\"Model built with final fc:\", model.fc.weight.shape)\n\n# try to load existing checkpoint into backbone (non-strict) if present\nckpt_path = Path(\"/kaggle/working/artifacts/classification_model.pt\")\nif ckpt_path.exists():\n    ck = torch.load(ckpt_path, map_location=device)\n    # quick heuristic to extract nested state dict\n    if isinstance(ck, dict) and 'model_state_dict' in ck:\n        sd = ck['model_state_dict']\n    elif isinstance(ck, dict) and 'state_dict' in ck:\n        sd = ck['state_dict']\n    else:\n        sd = ck\n    try:\n        model.load_state_dict(sd, strict=False)\n        print(\"Loaded checkpoint with strict=False\")\n    except Exception as e:\n        print(\"Load warning (non-fatal):\", e)\n\n# one optimization step on one batch\nopt = optim.Adam(model.parameters(), lr=1e-4)\ncriterion = nn.CrossEntropyLoss()\n\n# get a single batch\nstart = time.time()\nbatch = next(iter(train_loader))\nimgs, labels = batch\nprint(\"Batch shapes:\", imgs.shape, labels.shape)\nimgs, labels = imgs.to(device), labels.to(device)\n\nmodel.train()\nopt.zero_grad()\nout = model(imgs)\nloss = criterion(out, labels)\nprint(\"Loss on single batch:\", float(loss.item()))\nloss.backward()\nopt.step()\nprint(\"Single-step backward completed in {:.1f}s\".format(time.time()-start))\n# Done - model is trainable on one batch\nprint(\"PRELIGHT SUCCESS: data pipeline + model forward & backward OK.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T14:56:54.821827Z","iopub.execute_input":"2025-11-28T14:56:54.823273Z","iopub.status.idle":"2025-11-28T14:56:56.284654Z","shell.execute_reply.started":"2025-11-28T14:56:54.823217Z","shell.execute_reply":"2025-11-28T14:56:56.283936Z"}},"outputs":[{"name":"stdout","text":"Sanity: train_loader size: 333 val: 28\nModel built with final fc: torch.Size([2, 512])\nBatch shapes: torch.Size([8, 3, 224, 224]) torch.Size([8])\nLoss on single batch: 0.7018393278121948\nSingle-step backward completed in 1.3s\nPRELIGHT SUCCESS: data pipeline + model forward & backward OK.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# CELL 4 — Fine-tune training loop (CPU)\nimport torch\nfrom torch import nn, optim\nfrom tqdm import tqdm\nimport os\n\n# reuse objects created earlier: model, train_loader, val_loader, class_names\ndevice = \"cpu\"\nmodel.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-4)\nEPOCHS = 5  \nbest_val_acc = 0.0\nbest_path = Path(\"/kaggle/working/artifacts/classification_model_finetuned.pt\")\n\nfor epoch in range(1, EPOCHS+1):\n    model.train()\n    running_loss = 0.0\n    for imgs, labels in tqdm(train_loader, desc=f\"Epoch {epoch} train\"):\n        imgs, labels = imgs.to(device), labels.to(device)\n        optimizer.zero_grad()\n        out = model(imgs)\n        loss = criterion(out, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n    avg_loss = running_loss / max(1, len(train_loader))\n    print(f\"Epoch {epoch} training loss: {avg_loss:.4f}\")\n\n    # validation\n    model.eval()\n    correct = 0; total = 0\n    with torch.no_grad():\n        for imgs, labels in val_loader:\n            imgs, labels = imgs.to(device), labels.to(device)\n            out = model(imgs)\n            preds = out.argmax(dim=1)\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n    val_acc = correct / max(1, total)\n    print(f\"Epoch {epoch} validation accuracy: {val_acc:.4f}\")\n\n    # save best\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        torch.save(model.state_dict(), best_path)\n        print(\"Saved new best model to\", best_path)\n\nprint(\"Fine-tune done. Best val acc:\", best_val_acc)\nprint(\"Best model path:\", best_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T14:57:23.531740Z","iopub.execute_input":"2025-11-28T14:57:23.532106Z","iopub.status.idle":"2025-11-28T15:21:48.827331Z","shell.execute_reply.started":"2025-11-28T14:57:23.532080Z","shell.execute_reply":"2025-11-28T15:21:48.826164Z"}},"outputs":[{"name":"stderr","text":"Epoch 1 train: 100%|██████████| 333/333 [04:34<00:00,  1.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 training loss: 0.5254\nEpoch 1 validation accuracy: 0.6493\nSaved new best model to /kaggle/working/artifacts/classification_model_finetuned.pt\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2 train: 100%|██████████| 333/333 [04:34<00:00,  1.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 training loss: 0.3857\nEpoch 2 validation accuracy: 0.7534\nSaved new best model to /kaggle/working/artifacts/classification_model_finetuned.pt\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3 train: 100%|██████████| 333/333 [04:39<00:00,  1.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 training loss: 0.3382\nEpoch 3 validation accuracy: 0.7692\nSaved new best model to /kaggle/working/artifacts/classification_model_finetuned.pt\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4 train: 100%|██████████| 333/333 [04:36<00:00,  1.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 training loss: 0.2855\nEpoch 4 validation accuracy: 0.8281\nSaved new best model to /kaggle/working/artifacts/classification_model_finetuned.pt\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5 train: 100%|██████████| 333/333 [04:41<00:00,  1.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5 training loss: 0.2211\nEpoch 5 validation accuracy: 0.8258\nFine-tune done. Best val acc: 0.8280542986425339\nBest model path: /kaggle/working/artifacts/classification_model_finetuned.pt\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# CELL 5 — load best model and run a single-sample prediction (prints label)\nimport torch, random\nfrom torchvision import transforms as T\nfrom PIL import Image\nfrom pathlib import Path\nimport os\n\nBEST = Path(\"/kaggle/working/artifacts/classification_model_finetuned.pt\")\nif not BEST.exists():\n    BEST = Path(\"/kaggle/working/artifacts/classification_model.pt\")  # fallback\n\n# reconstruct model architecture then load\nfrom torchvision import models\nimport json\nclass_names = json.load(open(\"/kaggle/working/artifacts/class_names.json\",\"r\",encoding=\"utf-8\"))\nnum_classes = len(class_names)\nmodel_eval = models.resnet18(weights=None)\nnum_ftrs = model_eval.fc.in_features\nmodel_eval.fc = torch.nn.Linear(num_ftrs, num_classes)\nmodel_eval.load_state_dict(torch.load(BEST, map_location=\"cpu\"))\nmodel_eval.eval()\n\n# find a sample image from valid\nWORK_ROOT = Path(\"/kaggle/working/dataset_copy/classification_dataset\")\nif not WORK_ROOT.exists():\n    WORK_ROOT = Path(\"/kaggle/working/dataset_copy\")\n\nsample_img = None\nfor root, dirs, files in os.walk(WORK_ROOT / \"valid\"):\n    for f in files:\n        if f.lower().endswith(('.jpg','.jpeg','.png')):\n            sample_img = Path(root) / f\n            break\n    if sample_img:\n        break\n\nif sample_img is None:\n    # fallback: any image\n    for root, dirs, files in os.walk(WORK_ROOT):\n        for f in files:\n            if f.lower().endswith(('.jpg','.jpeg','.png')):\n                sample_img = Path(root) / f\n                break\n        if sample_img:\n            break\n\nprint(\"Sample image:\", sample_img)\ntf = T.Compose([T.Resize((224,224)), T.ToTensor()])\nimg = tf(Image.open(sample_img).convert(\"RGB\")).unsqueeze(0)\nwith torch.no_grad():\n    out = model_eval(img)\n    pred = int(out.argmax(dim=1).item())\nprint(\"Predicted index:\", pred, \"Predicted label:\", class_names[pred])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T15:22:14.985429Z","iopub.execute_input":"2025-11-28T15:22:14.985764Z","iopub.status.idle":"2025-11-28T15:22:15.201539Z","shell.execute_reply.started":"2025-11-28T15:22:14.985740Z","shell.execute_reply":"2025-11-28T15:22:15.200339Z"}},"outputs":[{"name":"stdout","text":"Sample image: /kaggle/working/dataset_copy/valid/bird/0527b2c8cde80736_jpg.rf.e7cfd4cdde3117b1c4797fe2a669281f.jpg\nPredicted index: 0 Predicted label: bird\n","output_type":"stream"}],"execution_count":9}]}